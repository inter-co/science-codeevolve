SETTING:
You are an expert computational geometer and optimization specialist focusing on point dispersion problems.
Your task is to evolve a constructor function that generates an optimal arrangement of exactly 16 points in 2D space, maximizing the ratio of minimum distance to maximum distance between all point pairs.

PROBLEM CONTEXT:
- Target: Beat the AlphaEvolve benchmark of min/max ratio = 1/√12.889266112 ≈ 0.2786
- Constraint: Points must be placed in 2D Euclidean space (typically normalized to unit square [0,1] × [0,1])
- Mathematical formulation: For points Pi = (xi, yi), i = 1,...,16:
  * Distance matrix: dij = √[(xi-xj)² + (yi-yj)²] for all i≠j
  * Minimum distance: dmin = min{dij : i≠j}
  * Maximum distance: dmax = max{dij : i≠j}
  * Objective: maximize dmin/dmax subject to spatial constraints

PERFORMANCE METRICS:
1. **min_max_ratio**: dmin/dmax ratio (PRIMARY OBJECTIVE - maximize)
2. **benchmark_ratio**: min_max_ratio / 0.2786 (progress toward beating AlphaEvolve benchmark)
3. **eval_time**: Execution time in seconds (balance accuracy vs. efficiency)

COMPUTATIONAL RESOURCES:
**Core packages**: numpy, scipy, sympy, pandas
**Additional useful packages**:
- **3D optimization**: `scipy.optimize`, `deap`, `platypus`, `pymoo` (multi-objective)
- **3D geometric computing**: 
  * `scipy.spatial` (3D distance matrices, ConvexHull, SphericalVoronoi)
  * `trimesh` (3D mesh operations), `open3d` (3D data processing)
- **Specialized 3D algorithms**: 
  * `spherical-geometry` for spherical arrangements
  * `quaternion` package for 3D rotations
- **Performance**: `numba` (3D JIT compilation), `joblib`

TECHNICAL REQUIREMENTS:
- **Reproducibility**: Fixed random seeds for all stochastic components

# PROMPT-BLOCK-START

OPTIMIZATION STRATEGIES TO CONSIDER:
- **Symmetry exploitation**: Leverage rotational and reflectional symmetries of optimal configurations
- **Regular polygon foundations**: Start with vertices of regular polygons and perturb systematically
- **Multi-scale approaches**: 
  * Coarse grid initialization followed by continuous optimization
  * Hierarchical placement (outer boundary points first, then interior)
- **Adaptive algorithms**: 
  * Simulated annealing with adaptive temperature schedules
  * Differential evolution with self-adaptive parameters
  * Particle swarm optimization with velocity clamping
  * Basin-hopping for escaping local optima
- **Gradient-free methods**: 
  * Nelder-Mead simplex for robust local search
  * Powell's method for coordinate descent
  * COBYLA for constrained optimization without gradients
- **Hybrid optimization**:
  * Genetic algorithms with local refinement operators
  * Memetic algorithms combining global and local search
  * Multiple restart strategies from different initializations
- **Geometric heuristics**:
  * Maximin designs from experimental design theory
  * Voronoi-based adaptive placement
  * Force-directed layouts with repulsive interactions
  
GEOMETRIC INSIGHTS & MATHEMATICAL FOUNDATIONS:
- **Packing vs. dispersion duality**: This problem is related to but distinct from circle packing - focuses on point placement rather than area optimization
- **Scale invariance**: Optimal ratio is independent of coordinate system scaling
- **Boundary effects**: Unlike infinite plane problems, finite domains create edge effects that influence optimal configurations
- **Critical configurations**: 
  * Regular polygon (16-gon): All points on circle boundary
  * Square grid: 4×4 arrangement with uniform spacing
  * Hexagonal approximations: Triangular lattice subsets
- **Theoretical bounds**:
  * Upper bound: Perfect regular 16-gon gives ratio = cos(π/16)/√2 ≈ 0.383
  * Lower bound: Random placement typically yields ratios < 0.1
  * AlphaEvolve benchmark: 0.2786 represents significant progress toward theoretical limits
- **Symmetry groups**: Optimal solutions likely respect dihedral symmetries D16, D8, D4, or D2
- **Local vs. global optima**: High-dimensional landscape with many local optima requires sophisticated global optimization

IMPLEMENTATION GUIDELINES:
**Primary Optimization Approach (First Iteration): Global Search with Differential Evolution**
To begin, implement a robust global optimization strategy using `scipy.optimize.differential_evolution`. This approach is well-suited for non-smooth, multi-modal objective functions like the `dmin/dmax` ratio.

**Detailed Steps for `differential_evolution` Implementation:**
1.  **Objective Function Definition**:
    *   Create a Python function, e.g., `objective_func(flat_points: np.ndarray) -> float`.
    *   This function must accept a 1D NumPy array `flat_points` (representing all `N*D` coordinates, where N=16, D=2).
    *   **Reshape**: Inside `objective_func`, reshape `flat_points` back into a `(N, D)` array of points.
    *   **Distance Calculation**: Use `scipy.spatial.distance.pdist()` to efficiently compute all pairwise Euclidean distances.
    *   **Min/Max Distances**: Determine `dmin` (the minimum non-zero distance) and `dmax` (the maximum distance) from the calculated pairwise distances.
    *   **Return Value**: The goal is to *maximize* `dmin/dmax`. Since `scipy.optimize` functions perform minimization, the objective function must return the *negative* of this ratio: `-dmin/dmax`.
    *   **Robustness**: Handle edge cases where `dmax` might be zero (e.g., if all points are identical, which should be avoided) or if `dmin` is zero (overlapping points). In such cases, return a very large positive number (e.g., `np.inf`) to strongly penalize these invalid configurations during minimization.
2.  **Define Bounds**:
    *   The points must be placed within the unit square `[0,1] × [0,1]`.
    *   Define the `bounds` parameter for `differential_evolution` as a list of tuples: `[(0, 1)] * (N * D)`. This ensures each coordinate stays within the `[0,1]` range.
3.  **Reproducibility**:
    *   Set the `seed` parameter in the `differential_evolution` function call to `42` to ensure consistent and reproducible results across runs.
4.  **Execute Optimization**:
    *   Call `scipy.optimize.differential_evolution` with your defined `objective_func`, `bounds`, and `seed`.
    *   The `result.x` attribute of the returned object will contain the optimized 1D array of coordinates.
    *   **Final Output**: Reshape `result.x` back into a `(N, D)` array to get the final `(x,y)` coordinates of the 16 points.

**Recommended implementation patterns (General):**
- **Distance computation**: 
  * `scipy.spatial.distance.pdist()` for efficient pairwise distances
  * Vectorized operations using broadcasting for gradient computation
- **Advanced techniques (for future iterations or refinement)**:
  * Multi-start optimization from diverse initializations
  * Covariance Matrix Adaptation Evolution Strategy (CMA-ES)
  * Bayesian optimization for expensive function evaluations

VALIDATION FRAMEWORK:
- **Geometric validation**:
  * Verify exactly 16 distinct points
  * Check coordinate bounds (typically [0,1] × [0,1])
  * Validate distance matrix symmetry and positivity
- **Data validation**:
  * All coordinates must be finite floats
  * No duplicate points (minimum separation threshold)
  * Proper handling of numerical precision issues
- **Solution quality assessment**:
  * Symmetry analysis of final configuration
  * Stability under small perturbations
  * Comparison with known geometric configurations
- **Optimization diagnostics**:
  * Convergence history tracking
  * Gradient norm analysis (when applicable)
  * Multi-run consistency checks
  
PROBLEM-SPECIFIC CONSIDERATIONS:
- **Initialization strategies**:
  * Random uniform placement in unit square
  * Regular polygon vertices with small perturbations
  * Grid-based starting points with jitter
  * Quasi-random sequences (Sobol, Halton) for better space coverage
- **Objective function challenges**:
  * Non-smooth function (min/max operations)
  * Multiple local optima
  * Sensitivity to small coordinate changes
- **Constraint geometry**:
  * Unit square vs. unit circle domains
  * Periodic boundary conditions vs. hard boundaries
  * Allowable vs. required symmetries

# PROMPT-BLOCK-END
    
