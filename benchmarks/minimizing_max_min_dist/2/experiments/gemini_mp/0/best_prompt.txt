SETTING:
You are an expert computational geometer and optimization specialist focusing on point dispersion problems.
Your task is to evolve a constructor function that generates an optimal arrangement of exactly 16 points in 2D space, maximizing the ratio of minimum distance to maximum distance between all point pairs.

PROBLEM CONTEXT:
- Target: Beat the AlphaEvolve benchmark of min/max ratio = 1/√12.889266112 ≈ 0.2786
- Constraint: Points must be placed in 2D Euclidean space (typically normalized to unit square [0,1] × [0,1])
- Mathematical formulation: For points Pi = (xi, yi), i = 1,...,16:
  * Distance matrix: dij = √[(xi-xj)² + (yi-yj)²] for all i≠j
  * Minimum distance: dmin = min{dij : i≠j}
  * Maximum distance: dmax = max{dij : i≠j}
  * Objective: maximize dmin/dmax subject to spatial constraints

PERFORMANCE METRICS:
1. **min_max_ratio**: dmin/dmax ratio (PRIMARY OBJECTIVE - maximize)
2. **benchmark_ratio**: min_max_ratio / 0.2786 (progress toward beating AlphaEvolve benchmark)
3. **eval_time**: Execution time in seconds (balance accuracy vs. efficiency)

COMPUTATIONAL RESOURCES:
**Core packages**: numpy, scipy, sympy, pandas
**Additional useful packages**:
- **3D optimization**: `scipy.optimize`, `deap`, `platypus`, `pymoo` (multi-objective)
- **3D geometric computing**: 
  * `scipy.spatial` (3D distance matrices, ConvexHull, SphericalVoronoi)
  * `trimesh` (3D mesh operations), `open3d` (3D data processing)
- **Specialized 3D algorithms**: 
  * `spherical-geometry` for spherical arrangements
  * `quaternion` package for 3D rotations
- **Performance**: `numba` (3D JIT compilation), `joblib`

TECHNICAL REQUIREMENTS:
- **Reproducibility**: Fixed random seeds for all stochastic components

# PROMPT-BLOCK-START

OPTIMIZATION STRATEGIES:
Given the problem's high-dimensional, non-smooth objective function with multiple local optima, a robust global optimization approach is essential. The primary goal is to find the global optimum within reasonable computational time, **strictly adhering to the `eval_time` constraint**. Overly aggressive parameter settings or redundant optimization steps will lead to timeouts.

**Primary Recommended Approach:**
Employ a global optimization algorithm capable of exploring the search space effectively. `scipy.optimize.differential_evolution` or `scipy.optimize.basinhopping` are highly recommended for this purpose, as they are well-suited for escaping local minima. **Crucially, prioritize a single, well-configured global search over multiple independent runs if computational time is a significant constraint.** A local refinement step (e.g., using `scipy.optimize.minimize` with 'L-BFGS-B') can be considered **once** after the global search to fine-tune the *best* solution found, but the global optimizer should yield a strong baseline.

- **Adaptive algorithms (Primary Global Search Candidates)**: 
  * Differential evolution with self-adaptive parameters (Highly Recommended for global search)
  * Basin-hopping for escaping local optima (Highly Recommended for global search)
  * Simulated annealing with adaptive temperature schedules
  * Particle swarm optimization with velocity clamping
- **Hybrid optimization**:
  * Multiple restart strategies from different initializations
  * Genetic algorithms with local refinement operators
  * Memetic algorithms combining global and local search
- **Gradient-free methods (for local refinement or alternative global search)**: 
  * Nelder-Mead simplex for robust local search
  * Powell's method for coordinate descent
  * COBYLA for constrained optimization without gradients
- **Symmetry exploitation**: Leverage rotational and reflectional symmetries of optimal configurations
- **Regular polygon foundations**: Start with vertices of regular polygons and perturb systematically
- **Multi-scale approaches**: 
  * Coarse grid initialization followed by continuous optimization
  * Hierarchical placement (outer boundary points first, then interior)
- **Geometric heuristics**:
  * Maximin designs from experimental design theory
  * Voronoi-based adaptive placement
  * Force-directed layouts with repulsive interactions
  
GEOMETRIC INSIGHTS & MATHEMATICAL FOUNDATIONS:
- **Packing vs. dispersion duality**: This problem is related to but distinct from circle packing - focuses on point placement rather than area optimization
- **Scale invariance**: Optimal ratio is independent of coordinate system scaling
- **Boundary effects**: Unlike infinite plane problems, finite domains create edge effects that influence optimal configurations
- **Critical configurations**: 
  * Regular polygon (16-gon): All points on circle boundary
  * Square grid: 4×4 arrangement with uniform spacing
  * Hexagonal approximations: Triangular lattice subsets
- **Theoretical bounds**:
  * Upper bound: Perfect regular 16-gon gives ratio = cos(π/16)/√2 ≈ 0.383
  * Lower bound: Random placement typically yields ratios < 0.1
  * AlphaEvolve benchmark: 0.2786 represents significant progress toward theoretical limits
- **Symmetry groups**: Optimal solutions likely respect dihedral symmetries D16, D8, D4, or D2
- **Local vs. global optima**: High-dimensional landscape with many local optima requires sophisticated global optimization

IMPLEMENTATION GUIDELINES:
**Detailed Steps for Implementation:**

1.  **Define the Objective Function (`objective_function`)**:
    *   **Input**: A 1D NumPy array `coords` representing the flattened `(x1, y1, x2, y2, ..., x16, y16)` coordinates of the 16 points.
    *   **Internal Logic**:
        *   Reshape `coords` into a `(16, 2)` 2D array of points.
        *   Compute the pairwise Euclidean distances between all points using `scipy.spatial.distance.pdist(points)`.
        *   Calculate `dmin` as the minimum of these distances and `dmax` as the maximum.
        *   **Critical Handling**: If `dmin` is zero (meaning two or more points coincide or are extremely close, e.g., `dmin < 1e-9`), return a very large number (e.g., `np.inf` or `1e10`) to heavily penalize such configurations, as this would result in a division by zero or an undefined ratio.
        *   Calculate the `min_max_ratio = dmin / dmax`.
    *   **Output**: Return `1.0 / min_max_ratio`. This converts the maximization problem (maximize `min_max_ratio`) into a minimization problem, which `scipy.optimize` solvers expect.

2.  **Set up Optimization Bounds**:
    *   The points must be within the unit square `[0,1] × [0,1]`.
    *   Define `bounds = [(0, 1)] * (num_points * num_dimensions)`. For 16 points in 2D, this means `[(0, 1)] * 32`.

3.  **Perform Global Optimization using `scipy.optimize.differential_evolution`**:
    *   **Call Signature**: `result = scipy.optimize.differential_evolution(objective_function, bounds, seed=42, ...)`
    *   **`objective_function`**: The function defined in step 1.
    *   **`bounds`**: The bounds defined in step 2.
    *   **`seed=42`**: Crucial for reproducibility, as specified in technical requirements. **Note: If multiple runs are desired for robustness, vary the seed for each run, but be mindful that total `eval_time` will multiply. Consider reducing `maxiter` and `popsize` per run if using multiple runs.**
    *   **`maxiter` and `popsize`**: Set these parameters carefully to balance solution quality and `eval_time`. The suggested range for `maxiter` is (e.g., 1000-5000) and `popsize` (e.g., 15-30). **Aggressively high values, especially when combined with multiple runs or subsequent local optimizations, are highly likely to exceed the time limit.** Prioritize a single, well-tuned `differential_evolution` run with `workers=-1` (to utilize all CPU cores) as the primary strategy to obtain a strong baseline within the time limits.
    *   **Local Refinement**: If a local refinement step using `scipy.optimize.minimize` is considered, it should ideally be applied **only once** to the *final best solution* obtained from the global search, not after every intermediate global search result if multiple runs are performed.

4.  **Extract and Return Optimal Points**:
    *   The `result.x` attribute will contain the flattened optimal coordinates found by `differential_evolution`.
    *   Reshape `result.x` back into a `(16, 2)` NumPy array. This array represents the optimal arrangement of points.

**Recommended Libraries and Functions:**
- `numpy`: For array manipulation and mathematical operations.
- `scipy.spatial.distance.pdist`: For efficient pairwise distance calculation within the objective function.
- `scipy.optimize.differential_evolution`: For the primary global optimization algorithm.
- `scipy.optimize.minimize` (e.g., with `method='L-BFGS-B'`): Can be used as an optional secondary local refinement step on `result.x` if desired, but `differential_evolution` should be sufficient for a strong baseline.

**Initialization strategies**:
- `differential_evolution` handles its own initial population generation within the specified bounds, so an explicit `x0` is not typically needed. The `init` parameter can be explored for more advanced initialization if desired (e.g., 'sobol', 'latinhypercube').

**Constraint handling**:
- The `bounds` parameter in `scipy.optimize.differential_evolution` directly handles the `[0,1]x[0,1]` spatial constraints without needing explicit penalty or projection methods within the objective function.

VALIDATION FRAMEWORK:
- **Geometric validation**:
  * Verify exactly 16 distinct points
  * Check coordinate bounds (typically [0,1] × [0,1])
  * Validate distance matrix symmetry and positivity
- **Data validation**:
  * All coordinates must be finite floats
  * No duplicate points (minimum separation threshold)
  * Proper handling of numerical precision issues
- **Solution quality assessment**:
  * Symmetry analysis of final configuration
  * Stability under small perturbations
  * Comparison with known geometric configurations
- **Optimization diagnostics**:
  * Convergence history tracking
  * Gradient norm analysis (when applicable)
  * Multi-run consistency checks
  
PROBLEM-SPECIFIC CONSIDERATIONS:
- **Initialization strategies**:
  * Random uniform placement in unit square
  * Regular polygon vertices with small perturbations
  * Grid-based starting points with jitter
  * Quasi-random sequences (Sobol, Halton) for better space coverage
- **Objective function challenges**:
  * Non-smooth function (min/max operations)
  * Multiple local optima
  * Sensitivity to small coordinate changes
- **Constraint geometry**:
  * Unit square vs. unit circle domains
  * Periodic boundary conditions vs. hard boundaries
  * Allowable vs. required symmetries

# PROMPT-BLOCK-END
    
